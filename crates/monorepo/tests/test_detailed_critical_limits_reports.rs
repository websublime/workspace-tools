//! Detailed Critical Limits Identification Reports System
//!
//! This module implements comprehensive reporting system for critical limits identification,
//! generating detailed technical and executive reports with historical analysis, trend
//! visualization, prediction models, and actionable recommendations for system optimization
//! and capacity planning.

use sublime_monorepo_tools::Result;
use std::collections::{HashMap, VecDeque, BTreeMap};
use std::sync::atomic::{AtomicBool, AtomicUsize, AtomicU64, Ordering};
use std::sync::{Arc, Mutex, RwLock};
use std::thread;
use std::time::{Duration, Instant, SystemTime};

/// Configuration for detailed critical limits reporting
#[derive(Debug, Clone)]
pub struct CriticalLimitsReportingConfig {
    /// Report generation interval in seconds
    pub report_generation_interval_secs: u64,
    /// Historical data retention period in days
    pub historical_retention_days: u64,
    /// Report formats to generate
    pub report_formats: Vec<ReportFormat>,
    /// Report types to generate
    pub report_types: Vec<ReportType>,
    /// Analysis depth level
    pub analysis_depth: AnalysisDepth,
    /// Enable predictive analysis in reports
    pub enable_predictive_analysis: bool,
    /// Enable trend visualization
    pub enable_trend_visualization: bool,
    /// Enable correlation analysis
    pub enable_correlation_analysis: bool,
    /// Enable comparative analysis
    pub enable_comparative_analysis: bool,
    /// Statistical confidence level for reports
    pub statistical_confidence_level: f64,
    /// Minimum data points for analysis
    pub min_data_points_for_analysis: usize,
    /// Enable automated recommendations
    pub enable_automated_recommendations: bool,
    /// Report distribution settings
    pub distribution_config: ReportDistributionConfig,
    /// Custom report templates
    pub custom_templates: HashMap<String, ReportTemplate>,
}

impl Default for CriticalLimitsReportingConfig {
    fn default() -> Self {
        Self {
            report_generation_interval_secs: 3600, // Generate reports every hour
            historical_retention_days: 90,         // Keep 90 days of data
            report_formats: vec![
                ReportFormat::Executive,
                ReportFormat::Technical,
                ReportFormat::Operational,
                ReportFormat::JSON,
            ],
            report_types: vec![
                ReportType::LimitsIdentification,
                ReportType::TrendAnalysis,
                ReportType::PredictiveForecasting,
                ReportType::PerformanceBaseline,
                ReportType::CapacityPlanning,
                ReportType::AlertsSummary,
                ReportType::RecoveryEffectiveness,
            ],
            analysis_depth: AnalysisDepth::Comprehensive,
            enable_predictive_analysis: true,
            enable_trend_visualization: true,
            enable_correlation_analysis: true,
            enable_comparative_analysis: true,
            statistical_confidence_level: 0.95, // 95% confidence
            min_data_points_for_analysis: 50,
            enable_automated_recommendations: true,
            distribution_config: ReportDistributionConfig::default(),
            custom_templates: HashMap::new(),
        }
    }
}

/// Report formats available
#[derive(Debug, Clone, PartialEq)]
pub enum ReportFormat {
    /// Executive summary format
    Executive,
    /// Technical detailed format
    Technical,
    /// Operational dashboard format
    Operational,
    /// JSON structured format
    JSON,
    /// CSV data format
    CSV,
    /// Markdown documentation format
    Markdown,
    /// Custom format using templates
    Custom(String),
}

/// Types of reports to generate
#[derive(Debug, Clone, PartialEq)]
pub enum ReportType {
    /// Critical limits identification report
    LimitsIdentification,
    /// Trend analysis report
    TrendAnalysis,
    /// Predictive forecasting report
    PredictiveForecasting,
    /// Performance baseline report
    PerformanceBaseline,
    /// Capacity planning report
    CapacityPlanning,
    /// Alerts and incidents summary
    AlertsSummary,
    /// Recovery effectiveness analysis
    RecoveryEffectiveness,
    /// System health assessment
    SystemHealth,
    /// Resource utilization analysis
    ResourceUtilization,
    /// Anomaly detection summary
    AnomalyDetection,
}

/// Analysis depth levels
#[derive(Debug, Clone, PartialEq)]
pub enum AnalysisDepth {
    /// Basic analysis with key metrics
    Basic,
    /// Standard analysis with trends
    Standard,
    /// Comprehensive analysis with predictions
    Comprehensive,
    /// Exhaustive analysis with correlations
    Exhaustive,
}

/// Report distribution configuration
#[derive(Debug, Clone)]
pub struct ReportDistributionConfig {
    /// Enable automatic report distribution
    pub enable_distribution: bool,
    /// Email recipients for different report types
    pub email_recipients: HashMap<ReportType, Vec<String>>,
    /// File system paths for report storage
    pub storage_paths: HashMap<ReportFormat, String>,
    /// Enable real-time dashboard updates
    pub enable_dashboard_updates: bool,
    /// API endpoints for report publishing
    pub api_endpoints: Vec<String>,
}

impl Default for ReportDistributionConfig {
    fn default() -> Self {
        Self {
            enable_distribution: false, // Conservative default
            email_recipients: HashMap::new(),
            storage_paths: HashMap::new(),
            enable_dashboard_updates: false,
            api_endpoints: Vec::new(),
        }
    }
}

/// Custom report template
#[derive(Debug, Clone)]
pub struct ReportTemplate {
    /// Template name
    pub name: String,
    /// Template format string
    pub format_string: String,
    /// Required data fields
    pub required_fields: Vec<String>,
    /// Optional data fields
    pub optional_fields: Vec<String>,
    /// Template metadata
    pub metadata: HashMap<String, String>,
}

/// Critical limits reporting system
#[derive(Debug)]
pub struct CriticalLimitsReportingSystem {
    /// Configuration for the reporting system
    config: CriticalLimitsReportingConfig,
    /// Historical limits data
    historical_data: Arc<Mutex<VecDeque<LimitsDataPoint>>>,
    /// Generated reports cache
    generated_reports: Arc<Mutex<HashMap<String, GeneratedReport>>>,
    /// Analysis results cache
    analysis_cache: Arc<Mutex<HashMap<String, AnalysisResult>>>,
    /// System control flags
    reporting_active: Arc<AtomicBool>,
    analysis_active: Arc<AtomicBool>,
    /// Report statistics
    report_statistics: Arc<Mutex<ReportStatistics>>,
    /// Trend analysis engine
    trend_analyzer: Arc<Mutex<TrendAnalysisEngine>>,
    /// Predictive model engine
    prediction_engine: Arc<Mutex<PredictionEngine>>,
    /// Report formatter
    report_formatter: Arc<Mutex<ReportFormatter>>,
}

/// Data point for limits analysis
#[derive(Debug, Clone)]
pub struct LimitsDataPoint {
    /// Timestamp of the data point
    pub timestamp: Instant,
    /// System metrics at this point
    pub metrics: SystemMetrics,
    /// Detected limits at this point
    pub detected_limits: HashMap<String, DetectedLimit>,
    /// System state information
    pub system_state: SystemStateSnapshot,
    /// Environmental factors
    pub environment: EnvironmentalFactors,
    /// Alerts active at this time
    pub active_alerts: Vec<ActiveAlert>,
}

/// System metrics snapshot
#[derive(Debug, Clone)]
pub struct SystemMetrics {
    /// Memory usage metrics
    pub memory: MemoryMetrics,
    /// CPU usage metrics
    pub cpu: CpuMetrics,
    /// I/O usage metrics
    pub io: IOMetrics,
    /// Network usage metrics
    pub network: NetworkMetrics,
    /// Application performance metrics
    pub performance: PerformanceMetrics,
    /// Resource limits metrics
    pub limits: LimitsMetrics,
}

/// Memory usage metrics
#[derive(Debug, Clone)]
pub struct MemoryMetrics {
    /// Total memory available (MB)
    pub total_mb: f64,
    /// Used memory (MB)
    pub used_mb: f64,
    /// Free memory (MB)
    pub free_mb: f64,
    /// Memory usage percentage
    pub usage_percent: f64,
    /// Memory pressure level
    pub pressure_level: f64,
    /// Swap usage (MB)
    pub swap_used_mb: f64,
    /// Cache usage (MB)
    pub cache_mb: f64,
}

/// CPU usage metrics
#[derive(Debug, Clone)]
pub struct CpuMetrics {
    /// Overall CPU usage percentage
    pub usage_percent: f64,
    /// Load averages (1m, 5m, 15m)
    pub load_averages: [f64; 3],
    /// CPU temperature (if available)
    pub temperature: Option<f64>,
    /// Number of active threads
    pub active_threads: usize,
    /// Context switches per second
    pub context_switches_per_sec: f64,
    /// CPU frequency (MHz)
    pub frequency_mhz: f64,
}

/// I/O usage metrics
#[derive(Debug, Clone)]
pub struct IOMetrics {
    /// Disk read rate (MB/s)
    pub disk_read_mb_per_sec: f64,
    /// Disk write rate (MB/s)
    pub disk_write_mb_per_sec: f64,
    /// Disk usage percentage
    pub disk_usage_percent: f64,
    /// I/O wait percentage
    pub io_wait_percent: f64,
    /// IOPS (operations per second)
    pub iops: f64,
    /// Average I/O latency (ms)
    pub avg_latency_ms: f64,
}

/// Network usage metrics
#[derive(Debug, Clone)]
pub struct NetworkMetrics {
    /// Network in rate (MB/s)
    pub in_mb_per_sec: f64,
    /// Network out rate (MB/s)
    pub out_mb_per_sec: f64,
    /// Packet loss rate
    pub packet_loss_rate: f64,
    /// Network latency (ms)
    pub latency_ms: f64,
    /// Active connections count
    pub active_connections: usize,
    /// Bandwidth utilization percentage
    pub bandwidth_utilization_percent: f64,
}

/// Application performance metrics
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    /// Request throughput (req/s)
    pub throughput_req_per_sec: f64,
    /// Average response time (ms)
    pub avg_response_time_ms: f64,
    /// 95th percentile response time (ms)
    pub p95_response_time_ms: f64,
    /// 99th percentile response time (ms)
    pub p99_response_time_ms: f64,
    /// Error rate percentage
    pub error_rate_percent: f64,
    /// Queue depth
    pub queue_depth: usize,
}

/// Resource limits metrics
#[derive(Debug, Clone)]
pub struct LimitsMetrics {
    /// File descriptors used/limit
    pub file_descriptors: (usize, usize),
    /// Processes count/limit
    pub processes: (usize, usize),
    /// Open files count/limit
    pub open_files: (usize, usize),
    /// Memory limit (soft/hard) in MB
    pub memory_limits: (f64, f64),
    /// CPU limits (soft/hard) percentage
    pub cpu_limits: (f64, f64),
    /// Connection pool usage/limit
    pub connection_pool: (usize, usize),
}

/// Detected limit information
#[derive(Debug, Clone)]
pub struct DetectedLimit {
    /// Limit type
    pub limit_type: String,
    /// Current value
    pub current_value: f64,
    /// Limit threshold
    pub threshold: f64,
    /// Distance to limit (percentage)
    pub distance_percent: f64,
    /// Severity level
    pub severity: LimitSeverity,
    /// Detection confidence
    pub confidence: f64,
    /// Predicted time to breach
    pub time_to_breach: Option<Duration>,
}

/// Limit severity levels
#[derive(Debug, Clone, PartialEq)]
pub enum LimitSeverity {
    /// Information level
    Info,
    /// Warning level
    Warning,
    /// Critical level
    Critical,
    /// Emergency level
    Emergency,
}

/// System state snapshot
#[derive(Debug, Clone)]
pub struct SystemStateSnapshot {
    /// Overall system health score (0.0-1.0)
    pub health_score: f64,
    /// System uptime
    pub uptime: Duration,
    /// System load level
    pub load_level: LoadLevel,
    /// Active services count
    pub active_services: usize,
    /// System version information
    pub version_info: String,
    /// Configuration hash
    pub config_hash: String,
}

/// System load levels
#[derive(Debug, Clone, PartialEq)]
pub enum LoadLevel {
    /// Low load
    Low,
    /// Normal load
    Normal,
    /// High load
    High,
    /// Overloaded
    Overloaded,
    /// Critical load
    Critical,
}

/// Environmental factors
#[derive(Debug, Clone)]
pub struct EnvironmentalFactors {
    /// External traffic level
    pub traffic_level: f64,
    /// Time of day (0.0-24.0)
    pub time_of_day: f64,
    /// Day of week (0-6, Sunday=0)
    pub day_of_week: u8,
    /// Seasonal factor
    pub seasonal_factor: f64,
    /// External dependencies health
    pub dependencies_health: f64,
    /// Maintenance window active
    pub maintenance_active: bool,
}

/// Active alert information
#[derive(Debug, Clone)]
pub struct ActiveAlert {
    /// Alert ID
    pub id: String,
    /// Alert type
    pub alert_type: String,
    /// Alert severity
    pub severity: AlertSeverity,
    /// Alert message
    pub message: String,
    /// Alert timestamp
    pub timestamp: Instant,
    /// Alert source
    pub source: String,
}

/// Alert severity levels
#[derive(Debug, Clone, PartialEq)]
pub enum AlertSeverity {
    /// Low severity
    Low,
    /// Medium severity
    Medium,
    /// High severity
    High,
    /// Critical severity
    Critical,
}

/// Generated report
#[derive(Debug, Clone)]
pub struct GeneratedReport {
    /// Report ID
    pub id: String,
    /// Report type
    pub report_type: ReportType,
    /// Report format
    pub format: ReportFormat,
    /// Generation timestamp
    pub generated_at: Instant,
    /// Report content
    pub content: String,
    /// Report metadata
    pub metadata: ReportMetadata,
    /// Analysis results included
    pub analysis_results: Vec<String>,
    /// File size in bytes
    pub size_bytes: usize,
}

/// Report metadata
#[derive(Debug, Clone)]
pub struct ReportMetadata {
    /// Report title
    pub title: String,
    /// Report description
    pub description: String,
    /// Data period covered
    pub data_period: (Instant, Instant),
    /// Number of data points analyzed
    pub data_points_count: usize,
    /// Analysis confidence level
    pub confidence_level: f64,
    /// Report tags
    pub tags: Vec<String>,
    /// Report version
    pub version: String,
}

/// Analysis result
#[derive(Debug, Clone)]
pub struct AnalysisResult {
    /// Analysis type
    pub analysis_type: String,
    /// Analysis timestamp
    pub timestamp: Instant,
    /// Key findings
    pub findings: Vec<Finding>,
    /// Statistical summary
    pub statistics: StatisticalSummary,
    /// Recommendations
    pub recommendations: Vec<Recommendation>,
    /// Confidence score
    pub confidence: f64,
}

/// Analysis finding
#[derive(Debug, Clone)]
pub struct Finding {
    /// Finding ID
    pub id: String,
    /// Finding type
    pub finding_type: FindingType,
    /// Finding description
    pub description: String,
    /// Severity level
    pub severity: FindingSeverity,
    /// Supporting data
    pub supporting_data: Vec<DataPoint>,
    /// Impact assessment
    pub impact: ImpactAssessment,
}

/// Types of findings
#[derive(Debug, Clone, PartialEq)]
pub enum FindingType {
    /// Performance degradation
    PerformanceDegradation,
    /// Resource bottleneck
    ResourceBottleneck,
    /// Capacity limit approaching
    CapacityLimitApproaching,
    /// Anomaly detected
    AnomalyDetected,
    /// Trend identified
    TrendIdentified,
    /// Correlation discovered
    CorrelationDiscovered,
    /// Prediction made
    PredictionMade,
}

/// Finding severity levels
#[derive(Debug, Clone, PartialEq)]
pub enum FindingSeverity {
    /// Informational
    Informational,
    /// Low severity
    Low,
    /// Medium severity
    Medium,
    /// High severity
    High,
    /// Critical severity
    Critical,
}

/// Data point for analysis
#[derive(Debug, Clone)]
pub struct DataPoint {
    /// Data timestamp
    pub timestamp: Instant,
    /// Data value
    pub value: f64,
    /// Data label/description
    pub label: String,
    /// Data source
    pub source: String,
}

/// Impact assessment
#[derive(Debug, Clone)]
pub struct ImpactAssessment {
    /// Performance impact score (0.0-1.0)
    pub performance_impact: f64,
    /// Availability impact score (0.0-1.0)
    pub availability_impact: f64,
    /// Cost impact score (0.0-1.0)
    pub cost_impact: f64,
    /// User experience impact score (0.0-1.0)
    pub user_experience_impact: f64,
    /// Overall impact score (0.0-1.0)
    pub overall_impact: f64,
}

/// Statistical summary
#[derive(Debug, Clone)]
pub struct StatisticalSummary {
    /// Mean value
    pub mean: f64,
    /// Median value
    pub median: f64,
    /// Standard deviation
    pub std_deviation: f64,
    /// Minimum value
    pub min: f64,
    /// Maximum value
    pub max: f64,
    /// 95th percentile
    pub p95: f64,
    /// 99th percentile
    pub p99: f64,
    /// Sample count
    pub sample_count: usize,
}

/// Recommendation
#[derive(Debug, Clone)]
pub struct Recommendation {
    /// Recommendation ID
    pub id: String,
    /// Recommendation type
    pub recommendation_type: RecommendationType,
    /// Recommendation title
    pub title: String,
    /// Detailed description
    pub description: String,
    /// Priority level
    pub priority: RecommendationPriority,
    /// Implementation difficulty
    pub difficulty: ImplementationDifficulty,
    /// Expected impact
    pub expected_impact: ImpactAssessment,
    /// Implementation timeline
    pub timeline: String,
    /// Associated costs
    pub cost_estimate: Option<String>,
}

/// Types of recommendations
#[derive(Debug, Clone, PartialEq)]
pub enum RecommendationType {
    /// Infrastructure scaling
    InfrastructureScaling,
    /// Performance optimization
    PerformanceOptimization,
    /// Configuration adjustment
    ConfigurationAdjustment,
    /// Capacity planning
    CapacityPlanning,
    /// Monitoring enhancement
    MonitoringEnhancement,
    /// Process improvement
    ProcessImprovement,
    /// Preventive maintenance
    PreventiveMaintenance,
}

/// Recommendation priority levels
#[derive(Debug, Clone, PartialEq)]
pub enum RecommendationPriority {
    /// Low priority
    Low,
    /// Medium priority
    Medium,
    /// High priority
    High,
    /// Critical priority
    Critical,
    /// Emergency priority
    Emergency,
}

/// Implementation difficulty levels
#[derive(Debug, Clone, PartialEq)]
pub enum ImplementationDifficulty {
    /// Easy to implement
    Easy,
    /// Moderate difficulty
    Moderate,
    /// Difficult to implement
    Difficult,
    /// Very difficult
    VeryDifficult,
    /// Requires significant resources
    RequiresSignificantResources,
}

/// Report statistics
#[derive(Debug, Clone)]
pub struct ReportStatistics {
    /// Total reports generated
    pub total_reports_generated: usize,
    /// Reports by type count
    pub reports_by_type: HashMap<ReportType, usize>,
    /// Reports by format count
    pub reports_by_format: HashMap<ReportFormat, usize>,
    /// Average generation time
    pub avg_generation_time: Duration,
    /// Total data points processed
    pub total_data_points_processed: usize,
    /// Analysis cache hit rate
    pub cache_hit_rate: f64,
    /// Report distribution success rate
    pub distribution_success_rate: f64,
}

/// Trend analysis engine
#[derive(Debug)]
pub struct TrendAnalysisEngine {
    /// Historical data for trend analysis
    trend_data: VecDeque<TrendDataPoint>,
    /// Detected trends
    detected_trends: Vec<DetectedTrend>,
    /// Trend analysis configuration
    config: TrendAnalysisConfig,
}

/// Trend data point
#[derive(Debug, Clone)]
pub struct TrendDataPoint {
    /// Timestamp
    pub timestamp: Instant,
    /// Metric name
    pub metric: String,
    /// Metric value
    pub value: f64,
    /// Data quality score
    pub quality: f64,
}

/// Detected trend
#[derive(Debug, Clone)]
pub struct DetectedTrend {
    /// Trend ID
    pub id: String,
    /// Metric name
    pub metric: String,
    /// Trend direction
    pub direction: TrendDirection,
    /// Trend strength (0.0-1.0)
    pub strength: f64,
    /// Trend duration
    pub duration: Duration,
    /// Trend slope
    pub slope: f64,
    /// Confidence level
    pub confidence: f64,
    /// Trend start time
    pub start_time: Instant,
}

/// Trend directions
#[derive(Debug, Clone, PartialEq)]
pub enum TrendDirection {
    /// Increasing trend
    Increasing,
    /// Decreasing trend
    Decreasing,
    /// Stable trend
    Stable,
    /// Oscillating trend
    Oscillating,
    /// Exponential growth
    ExponentialGrowth,
    /// Exponential decay
    ExponentialDecay,
}

/// Trend analysis configuration
#[derive(Debug, Clone)]
pub struct TrendAnalysisConfig {
    /// Minimum trend duration for detection
    pub min_trend_duration: Duration,
    /// Minimum trend strength for detection
    pub min_trend_strength: f64,
    /// Window size for trend analysis
    pub analysis_window_size: usize,
    /// Trend detection sensitivity
    pub detection_sensitivity: f64,
}

/// Prediction engine
#[derive(Debug)]
pub struct PredictionEngine {
    /// Prediction models
    models: HashMap<String, PredictionModel>,
    /// Prediction history
    prediction_history: Vec<PredictionResult>,
    /// Engine configuration
    config: PredictionEngineConfig,
}

/// Prediction model
#[derive(Debug, Clone)]
pub struct PredictionModel {
    /// Model name
    pub name: String,
    /// Model type
    pub model_type: ModelType,
    /// Model parameters
    pub parameters: HashMap<String, f64>,
    /// Model accuracy
    pub accuracy: f64,
    /// Training data count
    pub training_data_count: usize,
    /// Last training time
    pub last_trained: Instant,
}

/// Model types
#[derive(Debug, Clone, PartialEq)]
pub enum ModelType {
    /// Linear regression
    LinearRegression,
    /// Polynomial regression
    PolynomialRegression,
    /// Moving average
    MovingAverage,
    /// Exponential smoothing
    ExponentialSmoothing,
    /// ARIMA model
    ARIMA,
    /// Machine learning model
    MachineLearning,
}

/// Prediction result
#[derive(Debug, Clone)]
pub struct PredictionResult {
    /// Prediction ID
    pub id: String,
    /// Metric being predicted
    pub metric: String,
    /// Prediction timestamp
    pub timestamp: Instant,
    /// Predicted value
    pub predicted_value: f64,
    /// Prediction confidence
    pub confidence: f64,
    /// Prediction time horizon
    pub time_horizon: Duration,
    /// Model used
    pub model_name: String,
}

/// Prediction engine configuration
#[derive(Debug, Clone)]
pub struct PredictionEngineConfig {
    /// Default prediction horizon
    pub default_horizon: Duration,
    /// Minimum data points for prediction
    pub min_data_points: usize,
    /// Model retraining interval
    pub retraining_interval: Duration,
    /// Prediction confidence threshold
    pub confidence_threshold: f64,
}

/// Report formatter
#[derive(Debug)]
pub struct ReportFormatter {
    /// Format templates
    templates: HashMap<ReportFormat, String>,
    /// Formatting rules
    rules: Vec<FormattingRule>,
    /// Output configuration
    config: FormatterConfig,
}

/// Formatting rule
#[derive(Debug, Clone)]
pub struct FormattingRule {
    /// Rule name
    pub name: String,
    /// Pattern to match
    pub pattern: String,
    /// Replacement format
    pub replacement: String,
    /// Rule priority
    pub priority: u8,
}

/// Formatter configuration
#[derive(Debug, Clone)]
pub struct FormatterConfig {
    /// Enable syntax highlighting
    pub enable_syntax_highlighting: bool,
    /// Include charts in reports
    pub include_charts: bool,
    /// Chart format preference
    pub chart_format: ChartFormat,
    /// Report language
    pub language: String,
    /// Timezone for timestamps
    pub timezone: String,
}

/// Chart format options
#[derive(Debug, Clone, PartialEq)]
pub enum ChartFormat {
    /// ASCII art charts
    ASCII,
    /// Text-based charts
    Text,
    /// No charts
    None,
}

impl CriticalLimitsReportingSystem {
    /// Create new critical limits reporting system
    pub fn new(config: CriticalLimitsReportingConfig) -> Self {
        Self {
            config,
            historical_data: Arc::new(Mutex::new(VecDeque::new())),
            generated_reports: Arc::new(Mutex::new(HashMap::new())),
            analysis_cache: Arc::new(Mutex::new(HashMap::new())),
            reporting_active: Arc::new(AtomicBool::new(false)),
            analysis_active: Arc::new(AtomicBool::new(false)),
            report_statistics: Arc::new(Mutex::new(ReportStatistics::default())),
            trend_analyzer: Arc::new(Mutex::new(TrendAnalysisEngine::new())),
            prediction_engine: Arc::new(Mutex::new(PredictionEngine::new())),
            report_formatter: Arc::new(Mutex::new(ReportFormatter::new())),
        }
    }

    /// Start the reporting system
    pub fn start_reporting(&self) -> Result<()> {
        self.reporting_active.store(true, Ordering::SeqCst);
        self.analysis_active.store(true, Ordering::SeqCst);
        
        println!("ðŸ“Š Starting critical limits reporting system...");
        
        // Start data collection thread
        self.start_data_collection_thread()?;
        
        // Start analysis thread
        self.start_analysis_thread()?;
        
        // Start report generation thread
        self.start_report_generation_thread()?;
        
        // Start trend analysis thread
        if self.config.enable_trend_visualization {
            self.start_trend_analysis_thread()?;
        }
        
        // Start prediction thread
        if self.config.enable_predictive_analysis {
            self.start_prediction_thread()?;
        }
        
        Ok(())
    }

    /// Start data collection thread
    fn start_data_collection_thread(&self) -> Result<()> {
        let reporting_active = Arc::clone(&self.reporting_active);
        let historical_data = Arc::clone(&self.historical_data);
        let config = self.config.clone();
        
        thread::spawn(move || {
            println!("ðŸ“Š Starting data collection thread...");
            
            while reporting_active.load(Ordering::SeqCst) {
                if let Ok(data_point) = Self::collect_limits_data_point() {
                    let mut data = historical_data.lock().unwrap();
                    data.push_back(data_point);
                    
                    // Maintain retention period
                    let retention_duration = Duration::from_secs(config.historical_retention_days * 24 * 3600);
                    let cutoff_time = Instant::now() - retention_duration;
                    
                    while let Some(front) = data.front() {
                        if front.timestamp < cutoff_time {
                            data.pop_front();
                        } else {
                            break;
                        }
                    }
                }
                
                thread::sleep(Duration::from_secs(60)); // Collect data every minute
            }
            
            println!("ðŸ”š Data collection thread stopped");
        });
        
        Ok(())
    }

    /// Start analysis thread
    fn start_analysis_thread(&self) -> Result<()> {
        let analysis_active = Arc::clone(&self.analysis_active);
        let historical_data = Arc::clone(&self.historical_data);
        let analysis_cache = Arc::clone(&self.analysis_cache);
        let config = self.config.clone();
        
        thread::spawn(move || {
            println!("ðŸ” Starting analysis thread...");
            
            while analysis_active.load(Ordering::SeqCst) {
                thread::sleep(Duration::from_secs(300)); // Analyze every 5 minutes
                
                if analysis_active.load(Ordering::SeqCst) {
                    let data = historical_data.lock().unwrap();
                    if data.len() >= config.min_data_points_for_analysis {
                        Self::perform_comprehensive_analysis_static(&data, &analysis_cache, &config);
                    }
                }
            }
            
            println!("ðŸ”š Analysis thread stopped");
        });
        
        Ok(())
    }

    /// Start report generation thread
    fn start_report_generation_thread(&self) -> Result<()> {
        let reporting_active = Arc::clone(&self.reporting_active);
        let historical_data = Arc::clone(&self.historical_data);
        let analysis_cache = Arc::clone(&self.analysis_cache);
        let generated_reports = Arc::clone(&self.generated_reports);
        let report_statistics = Arc::clone(&self.report_statistics);
        let report_formatter = Arc::clone(&self.report_formatter);
        let config = self.config.clone();
        
        thread::spawn(move || {
            println!("ðŸ“‹ Starting report generation thread...");
            
            while reporting_active.load(Ordering::SeqCst) {
                thread::sleep(Duration::from_secs(config.report_generation_interval_secs));
                
                if reporting_active.load(Ordering::SeqCst) {
                    Self::generate_all_reports_static(
                        &historical_data,
                        &analysis_cache,
                        &generated_reports,
                        &report_statistics,
                        &report_formatter,
                        &config,
                    );
                }
            }
            
            println!("ðŸ”š Report generation thread stopped");
        });
        
        Ok(())
    }

    /// Start trend analysis thread
    fn start_trend_analysis_thread(&self) -> Result<()> {
        let analysis_active = Arc::clone(&self.analysis_active);
        let historical_data = Arc::clone(&self.historical_data);
        let trend_analyzer = Arc::clone(&self.trend_analyzer);
        
        thread::spawn(move || {
            println!("ðŸ“ˆ Starting trend analysis thread...");
            
            while analysis_active.load(Ordering::SeqCst) {
                thread::sleep(Duration::from_secs(600)); // Analyze trends every 10 minutes
                
                if analysis_active.load(Ordering::SeqCst) {
                    let data = historical_data.lock().unwrap();
                    if data.len() >= 20 {
                        Self::analyze_trends_static(&data, &trend_analyzer);
                    }
                }
            }
            
            println!("ðŸ”š Trend analysis thread stopped");
        });
        
        Ok(())
    }

    /// Start prediction thread
    fn start_prediction_thread(&self) -> Result<()> {
        let analysis_active = Arc::clone(&self.analysis_active);
        let historical_data = Arc::clone(&self.historical_data);
        let prediction_engine = Arc::clone(&self.prediction_engine);
        
        thread::spawn(move || {
            println!("ðŸ”® Starting prediction thread...");
            
            while analysis_active.load(Ordering::SeqCst) {
                thread::sleep(Duration::from_secs(900)); // Generate predictions every 15 minutes
                
                if analysis_active.load(Ordering::SeqCst) {
                    let data = historical_data.lock().unwrap();
                    if data.len() >= 50 {
                        Self::generate_predictions_static(&data, &prediction_engine);
                    }
                }
            }
            
            println!("ðŸ”š Prediction thread stopped");
        });
        
        Ok(())
    }

    /// Collect limits data point
    fn collect_limits_data_point() -> Result<LimitsDataPoint> {
        let now = Instant::now();
        
        // Simulate realistic data collection
        let base_load = 0.4 + (now.elapsed().as_secs() as f64 / 100.0) % 0.3;
        let noise = (now.elapsed().as_nanos() % 1000) as f64 / 10000.0;
        
        let metrics = SystemMetrics {
            memory: MemoryMetrics {
                total_mb: 16384.0,
                used_mb: 6144.0 + base_load * 4096.0 + noise * 512.0,
                free_mb: 10240.0 - (base_load * 4096.0),
                usage_percent: 37.5 + base_load * 25.0 + noise * 3.0,
                pressure_level: base_load + noise * 0.1,
                swap_used_mb: base_load * 1024.0,
                cache_mb: 2048.0 + base_load * 512.0,
            },
            cpu: CpuMetrics {
                usage_percent: 20.0 + base_load * 40.0 + noise * 5.0,
                load_averages: [
                    0.5 + base_load * 2.0,
                    0.4 + base_load * 1.8,
                    0.3 + base_load * 1.6,
                ],
                temperature: Some(45.0 + base_load * 15.0),
                active_threads: (100 + (base_load * 200.0) as usize),
                context_switches_per_sec: 1000.0 + base_load * 2000.0,
                frequency_mhz: 2400.0 + base_load * 400.0,
            },
            io: IOMetrics {
                disk_read_mb_per_sec: 10.0 + base_load * 30.0,
                disk_write_mb_per_sec: 5.0 + base_load * 20.0,
                disk_usage_percent: 45.0 + base_load * 10.0,
                io_wait_percent: base_load * 5.0,
                iops: 500.0 + base_load * 1000.0,
                avg_latency_ms: 2.0 + base_load * 3.0,
            },
            network: NetworkMetrics {
                in_mb_per_sec: 1.0 + base_load * 10.0,
                out_mb_per_sec: 0.8 + base_load * 8.0,
                packet_loss_rate: base_load * 0.01,
                latency_ms: 5.0 + base_load * 10.0,
                active_connections: (50 + (base_load * 200.0) as usize),
                bandwidth_utilization_percent: 10.0 + base_load * 30.0,
            },
            performance: PerformanceMetrics {
                throughput_req_per_sec: 1000.0 - base_load * 300.0,
                avg_response_time_ms: 50.0 + base_load * 100.0,
                p95_response_time_ms: 80.0 + base_load * 150.0,
                p99_response_time_ms: 120.0 + base_load * 200.0,
                error_rate_percent: base_load * 2.0,
                queue_depth: (base_load * 20.0) as usize,
            },
            limits: LimitsMetrics {
                file_descriptors: ((1000.0 + base_load * 2000.0) as usize, 8192),
                processes: ((50.0 + base_load * 100.0) as usize, 512),
                open_files: ((200.0 + base_load * 500.0) as usize, 2048),
                memory_limits: (8192.0, 16384.0),
                cpu_limits: (80.0, 95.0),
                connection_pool: ((base_load * 80.0) as usize, 200),
            },
        };
        
        let mut detected_limits = HashMap::new();
        
        // Detect memory limit
        if metrics.memory.usage_percent > 70.0 {
            detected_limits.insert("memory".to_string(), DetectedLimit {
                limit_type: "memory".to_string(),
                current_value: metrics.memory.usage_percent,
                threshold: 85.0,
                distance_percent: (85.0 - metrics.memory.usage_percent) / 85.0 * 100.0,
                severity: if metrics.memory.usage_percent > 80.0 { LimitSeverity::Critical } else { LimitSeverity::Warning },
                confidence: 0.9,
                time_to_breach: if metrics.memory.usage_percent > 75.0 { Some(Duration::from_secs(1800)) } else { None },
            });
        }
        
        // Detect CPU limit
        if metrics.cpu.usage_percent > 60.0 {
            detected_limits.insert("cpu".to_string(), DetectedLimit {
                limit_type: "cpu".to_string(),
                current_value: metrics.cpu.usage_percent,
                threshold: 90.0,
                distance_percent: (90.0 - metrics.cpu.usage_percent) / 90.0 * 100.0,
                severity: if metrics.cpu.usage_percent > 80.0 { LimitSeverity::Critical } else { LimitSeverity::Warning },
                confidence: 0.85,
                time_to_breach: if metrics.cpu.usage_percent > 70.0 { Some(Duration::from_secs(3600)) } else { None },
            });
        }
        
        let system_state = SystemStateSnapshot {
            health_score: 1.0 - (base_load + noise * 0.1).min(0.4),
            uptime: Duration::from_secs(86400 + now.elapsed().as_secs()),
            load_level: if base_load > 0.6 { LoadLevel::High } else if base_load > 0.4 { LoadLevel::Normal } else { LoadLevel::Low },
            active_services: 25,
            version_info: "v1.0.0".to_string(),
            config_hash: "abc123def456".to_string(),
        };
        
        let environment = EnvironmentalFactors {
            traffic_level: base_load,
            time_of_day: 12.0, // Noon
            day_of_week: 2,    // Tuesday
            seasonal_factor: 1.0,
            dependencies_health: 0.95,
            maintenance_active: false,
        };
        
        let mut active_alerts = Vec::new();
        if base_load > 0.6 {
            active_alerts.push(ActiveAlert {
                id: "alert_001".to_string(),
                alert_type: "high_load".to_string(),
                severity: AlertSeverity::Medium,
                message: "System load is elevated".to_string(),
                timestamp: now,
                source: "monitoring".to_string(),
            });
        }
        
        Ok(LimitsDataPoint {
            timestamp: now,
            metrics,
            detected_limits,
            system_state,
            environment,
            active_alerts,
        })
    }

    /// Perform comprehensive analysis
    fn perform_comprehensive_analysis_static(
        data: &VecDeque<LimitsDataPoint>,
        analysis_cache: &Arc<Mutex<HashMap<String, AnalysisResult>>>,
        config: &CriticalLimitsReportingConfig,
    ) {
        let analysis_id = format!("analysis_{}", Instant::now().elapsed().as_secs());
        
        let mut findings = Vec::new();
        
        // Analyze memory usage trends
        let memory_values: Vec<f64> = data.iter().map(|d| d.metrics.memory.usage_percent).collect();
        if let Some(memory_trend) = Self::detect_trend(&memory_values) {
            if memory_trend.abs() > 1.0 { // Significant trend
                findings.push(Finding {
                    id: "memory_trend_001".to_string(),
                    finding_type: FindingType::TrendIdentified,
                    description: format!("Memory usage trend detected: {:.2}% change per hour", memory_trend),
                    severity: if memory_trend > 5.0 { FindingSeverity::High } else { FindingSeverity::Medium },
                    supporting_data: Self::create_data_points(&memory_values, "memory_usage_percent"),
                    impact: ImpactAssessment {
                        performance_impact: memory_trend.abs() / 10.0,
                        availability_impact: if memory_trend > 0.0 { memory_trend / 20.0 } else { 0.0 },
                        cost_impact: 0.1,
                        user_experience_impact: memory_trend.abs() / 15.0,
                        overall_impact: memory_trend.abs() / 12.0,
                    },
                });
            }
        }
        
        // Analyze CPU usage patterns
        let cpu_values: Vec<f64> = data.iter().map(|d| d.metrics.cpu.usage_percent).collect();
        if let Some(cpu_trend) = Self::detect_trend(&cpu_values) {
            if cpu_trend.abs() > 2.0 {
                findings.push(Finding {
                    id: "cpu_trend_001".to_string(),
                    finding_type: FindingType::TrendIdentified,
                    description: format!("CPU usage trend detected: {:.2}% change per hour", cpu_trend),
                    severity: if cpu_trend > 10.0 { FindingSeverity::Critical } else { FindingSeverity::Medium },
                    supporting_data: Self::create_data_points(&cpu_values, "cpu_usage_percent"),
                    impact: ImpactAssessment {
                        performance_impact: cpu_trend.abs() / 8.0,
                        availability_impact: if cpu_trend > 0.0 { cpu_trend / 15.0 } else { 0.0 },
                        cost_impact: cpu_trend.abs() / 20.0,
                        user_experience_impact: cpu_trend.abs() / 10.0,
                        overall_impact: cpu_trend.abs() / 10.0,
                    },
                });
            }
        }
        
        // Check for capacity limits approaching
        if let Some(latest) = data.back() {
            for (limit_type, limit) in &latest.detected_limits {
                if limit.distance_percent < 20.0 { // Within 20% of limit
                    findings.push(Finding {
                        id: format!("capacity_limit_{}", limit_type),
                        finding_type: FindingType::CapacityLimitApproaching,
                        description: format!("{} limit approaching: {:.1}% used, {:.1}% remaining", 
                            limit_type, limit.current_value, limit.distance_percent),
                        severity: match limit.severity {
                            LimitSeverity::Critical | LimitSeverity::Emergency => FindingSeverity::Critical,
                            LimitSeverity::Warning => FindingSeverity::High,
                            LimitSeverity::Info => FindingSeverity::Medium,
                        },
                        supporting_data: vec![DataPoint {
                            timestamp: latest.timestamp,
                            value: limit.current_value,
                            label: format!("{}_current_value", limit_type),
                            source: "limits_detection".to_string(),
                        }],
                        impact: ImpactAssessment {
                            performance_impact: (100.0 - limit.distance_percent) / 100.0,
                            availability_impact: (100.0 - limit.distance_percent) / 100.0,
                            cost_impact: 0.3,
                            user_experience_impact: (100.0 - limit.distance_percent) / 100.0,
                            overall_impact: (100.0 - limit.distance_percent) / 100.0,
                        },
                    });
                }
            }
        }
        
        // Calculate statistics
        let statistics = if !memory_values.is_empty() {
            Self::calculate_statistics(&memory_values)
        } else {
            StatisticalSummary {
                mean: 0.0, median: 0.0, std_deviation: 0.0, min: 0.0, max: 0.0,
                p95: 0.0, p99: 0.0, sample_count: 0,
            }
        };
        
        // Generate recommendations
        let recommendations = Self::generate_recommendations_from_findings(&findings);
        
        let analysis_result = AnalysisResult {
            analysis_type: "comprehensive_limits_analysis".to_string(),
            timestamp: Instant::now(),
            findings,
            statistics,
            recommendations,
            confidence: config.statistical_confidence_level,
        };
        
        analysis_cache.lock().unwrap().insert(analysis_id, analysis_result);
    }

    /// Detect trend in data
    fn detect_trend(values: &[f64]) -> Option<f64> {
        if values.len() < 3 {
            return None;
        }
        
        let n = values.len() as f64;
        let sum_x: f64 = (0..values.len()).map(|i| i as f64).sum();
        let sum_y: f64 = values.iter().sum();
        let sum_xy: f64 = values.iter().enumerate().map(|(i, &y)| i as f64 * y).sum();
        let sum_x2: f64 = (0..values.len()).map(|i| (i as f64).powi(2)).sum();
        
        if n * sum_x2 - sum_x * sum_x == 0.0 {
            return None;
        }
        
        let slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x);
        Some(slope)
    }

    /// Create data points from values
    fn create_data_points(values: &[f64], label: &str) -> Vec<DataPoint> {
        values.iter().enumerate().map(|(i, &value)| {
            DataPoint {
                timestamp: Instant::now() - Duration::from_secs((values.len() - i) as u64 * 60),
                value,
                label: label.to_string(),
                source: "metrics_collection".to_string(),
            }
        }).collect()
    }

    /// Calculate statistical summary
    fn calculate_statistics(values: &[f64]) -> StatisticalSummary {
        if values.is_empty() {
            return StatisticalSummary {
                mean: 0.0, median: 0.0, std_deviation: 0.0, min: 0.0, max: 0.0,
                p95: 0.0, p99: 0.0, sample_count: 0,
            };
        }
        
        let mut sorted_values = values.to_vec();
        sorted_values.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let mean = values.iter().sum::<f64>() / values.len() as f64;
        let median = sorted_values[sorted_values.len() / 2];
        let variance = values.iter().map(|v| (v - mean).powi(2)).sum::<f64>() / values.len() as f64;
        let std_deviation = variance.sqrt();
        
        let p95_index = (sorted_values.len() as f64 * 0.95) as usize;
        let p99_index = (sorted_values.len() as f64 * 0.99) as usize;
        
        StatisticalSummary {
            mean,
            median,
            std_deviation,
            min: sorted_values[0],
            max: sorted_values[sorted_values.len() - 1],
            p95: sorted_values[p95_index.min(sorted_values.len() - 1)],
            p99: sorted_values[p99_index.min(sorted_values.len() - 1)],
            sample_count: values.len(),
        }
    }

    /// Generate recommendations from findings
    fn generate_recommendations_from_findings(findings: &[Finding]) -> Vec<Recommendation> {
        let mut recommendations = Vec::new();
        
        for finding in findings {
            match finding.finding_type {
                FindingType::CapacityLimitApproaching => {
                    recommendations.push(Recommendation {
                        id: format!("rec_{}", finding.id),
                        recommendation_type: RecommendationType::CapacityPlanning,
                        title: "Increase resource capacity".to_string(),
                        description: format!("Consider scaling up resources for {}", finding.description),
                        priority: match finding.severity {
                            FindingSeverity::Critical => RecommendationPriority::Critical,
                            FindingSeverity::High => RecommendationPriority::High,
                            _ => RecommendationPriority::Medium,
                        },
                        difficulty: ImplementationDifficulty::Moderate,
                        expected_impact: finding.impact.clone(),
                        timeline: "1-2 weeks".to_string(),
                        cost_estimate: Some("Medium".to_string()),
                    });
                },
                FindingType::TrendIdentified => {
                    recommendations.push(Recommendation {
                        id: format!("rec_{}", finding.id),
                        recommendation_type: RecommendationType::MonitoringEnhancement,
                        title: "Enhanced monitoring for trend".to_string(),
                        description: format!("Implement enhanced monitoring for the trend: {}", finding.description),
                        priority: RecommendationPriority::Medium,
                        difficulty: ImplementationDifficulty::Easy,
                        expected_impact: ImpactAssessment {
                            performance_impact: 0.1,
                            availability_impact: 0.1,
                            cost_impact: 0.05,
                            user_experience_impact: 0.05,
                            overall_impact: 0.1,
                        },
                        timeline: "1 week".to_string(),
                        cost_estimate: Some("Low".to_string()),
                    });
                },
                _ => {},
            }
        }
        
        recommendations
    }

    /// Generate all reports
    fn generate_all_reports_static(
        historical_data: &Arc<Mutex<VecDeque<LimitsDataPoint>>>,
        analysis_cache: &Arc<Mutex<HashMap<String, AnalysisResult>>>,
        generated_reports: &Arc<Mutex<HashMap<String, GeneratedReport>>>,
        report_statistics: &Arc<Mutex<ReportStatistics>>,
        report_formatter: &Arc<Mutex<ReportFormatter>>,
        config: &CriticalLimitsReportingConfig,
    ) {
        let data = historical_data.lock().unwrap();
        let analysis = analysis_cache.lock().unwrap();
        
        if data.len() < config.min_data_points_for_analysis {
            return;
        }
        
        for report_type in &config.report_types {
            for report_format in &config.report_formats {
                let report_id = format!("{}_{:?}_{}", 
                    format!("{:?}", report_type).to_lowercase(),
                    report_format,
                    Instant::now().elapsed().as_secs()
                );
                
                if let Ok(report_content) = Self::generate_report_content(
                    report_type,
                    report_format,
                    &data,
                    &analysis,
                    config,
                ) {
                    let report = GeneratedReport {
                        id: report_id.clone(),
                        report_type: report_type.clone(),
                        format: report_format.clone(),
                        generated_at: Instant::now(),
                        content: report_content.clone(),
                        metadata: ReportMetadata {
                            title: format!("{:?} Report", report_type),
                            description: format!("Critical limits analysis report in {:?} format", report_format),
                            data_period: (data.front().unwrap().timestamp, data.back().unwrap().timestamp),
                            data_points_count: data.len(),
                            confidence_level: config.statistical_confidence_level,
                            tags: vec!["limits".to_string(), "analysis".to_string()],
                            version: "1.0".to_string(),
                        },
                        analysis_results: analysis.keys().cloned().collect(),
                        size_bytes: report_content.len(),
                    };
                    
                    generated_reports.lock().unwrap().insert(report_id, report);
                    
                    // Update statistics
                    let mut stats = report_statistics.lock().unwrap();
                    stats.total_reports_generated += 1;
                    *stats.reports_by_type.entry(report_type.clone()).or_insert(0) += 1;
                    *stats.reports_by_format.entry(report_format.clone()).or_insert(0) += 1;
                }
            }
        }
    }

    /// Generate report content
    fn generate_report_content(
        report_type: &ReportType,
        report_format: &ReportFormat,
        data: &VecDeque<LimitsDataPoint>,
        analysis: &HashMap<String, AnalysisResult>,
        config: &CriticalLimitsReportingConfig,
    ) -> Result<String> {
        match report_format {
            ReportFormat::Executive => Self::generate_executive_report(report_type, data, analysis),
            ReportFormat::Technical => Self::generate_technical_report(report_type, data, analysis),
            ReportFormat::Operational => Self::generate_operational_report(report_type, data, analysis),
            ReportFormat::JSON => Self::generate_json_report(report_type, data, analysis),
            _ => Self::generate_basic_report(report_type, data, analysis),
        }
    }

    /// Generate executive report
    fn generate_executive_report(
        report_type: &ReportType,
        data: &VecDeque<LimitsDataPoint>,
        analysis: &HashMap<String, AnalysisResult>,
    ) -> Result<String> {
        let mut report = String::new();
        
        report.push_str("# Executive Summary - Critical Limits Analysis\n\n");
        report.push_str("## Key Findings\n\n");
        
        // Summary statistics
        if let Some(latest) = data.back() {
            report.push_str(&format!("- **System Health Score**: {:.1}%\n", latest.system_state.health_score * 100.0));
            report.push_str(&format!("- **Active Alerts**: {}\n", latest.active_alerts.len()));
            report.push_str(&format!("- **Critical Limits Detected**: {}\n", latest.detected_limits.len()));
        }
        
        report.push_str("\n## Recommendations\n\n");
        
        // High-level recommendations
        for analysis_result in analysis.values() {
            for recommendation in &analysis_result.recommendations {
                if matches!(recommendation.priority, RecommendationPriority::Critical | RecommendationPriority::High) {
                    report.push_str(&format!("- **{}**: {}\n", recommendation.title, recommendation.description));
                }
            }
        }
        
        report.push_str("\n## Risk Assessment\n\n");
        
        // Risk summary
        let critical_findings = analysis.values()
            .flat_map(|a| &a.findings)
            .filter(|f| matches!(f.severity, FindingSeverity::Critical | FindingSeverity::High))
            .count();
        
        report.push_str(&format!("- **Critical/High Severity Issues**: {}\n", critical_findings));
        report.push_str(&format!("- **Data Analysis Confidence**: {:.1}%\n", 
            analysis.values().map(|a| a.confidence).sum::<f64>() / analysis.len() as f64 * 100.0
        ));
        
        Ok(report)
    }

    /// Generate technical report
    fn generate_technical_report(
        report_type: &ReportType,
        data: &VecDeque<LimitsDataPoint>,
        analysis: &HashMap<String, AnalysisResult>,
    ) -> Result<String> {
        let mut report = String::new();
        
        report.push_str("# Technical Analysis Report - Critical Limits\n\n");
        report.push_str("## System Metrics Overview\n\n");
        
        if let Some(latest) = data.back() {
            report.push_str("### Memory Metrics\n");
            report.push_str(&format!("- Total Memory: {:.1} MB\n", latest.metrics.memory.total_mb));
            report.push_str(&format!("- Used Memory: {:.1} MB ({:.1}%)\n", 
                latest.metrics.memory.used_mb, latest.metrics.memory.usage_percent));
            report.push_str(&format!("- Memory Pressure: {:.2}\n", latest.metrics.memory.pressure_level));
            
            report.push_str("\n### CPU Metrics\n");
            report.push_str(&format!("- CPU Usage: {:.1}%\n", latest.metrics.cpu.usage_percent));
            report.push_str(&format!("- Load Averages: {:.2}, {:.2}, {:.2}\n", 
                latest.metrics.cpu.load_averages[0],
                latest.metrics.cpu.load_averages[1],
                latest.metrics.cpu.load_averages[2]
            ));
            report.push_str(&format!("- Active Threads: {}\n", latest.metrics.cpu.active_threads));
            
            report.push_str("\n### Performance Metrics\n");
            report.push_str(&format!("- Throughput: {:.1} req/s\n", latest.metrics.performance.throughput_req_per_sec));
            report.push_str(&format!("- Avg Response Time: {:.1} ms\n", latest.metrics.performance.avg_response_time_ms));
            report.push_str(&format!("- Error Rate: {:.2}%\n", latest.metrics.performance.error_rate_percent));
        }
        
        report.push_str("\n## Detailed Analysis Results\n\n");
        
        for (analysis_id, analysis_result) in analysis {
            report.push_str(&format!("### Analysis: {}\n", analysis_id));
            report.push_str(&format!("- **Confidence**: {:.1}%\n", analysis_result.confidence * 100.0));
            report.push_str(&format!("- **Findings Count**: {}\n", analysis_result.findings.len()));
            
            for finding in &analysis_result.findings {
                report.push_str(&format!("\n#### Finding: {}\n", finding.id));
                report.push_str(&format!("- **Type**: {:?}\n", finding.finding_type));
                report.push_str(&format!("- **Severity**: {:?}\n", finding.severity));
                report.push_str(&format!("- **Description**: {}\n", finding.description));
                report.push_str(&format!("- **Overall Impact**: {:.2}\n", finding.impact.overall_impact));
            }
        }
        
        Ok(report)
    }

    /// Generate operational report
    fn generate_operational_report(
        report_type: &ReportType,
        data: &VecDeque<LimitsDataPoint>,
        analysis: &HashMap<String, AnalysisResult>,
    ) -> Result<String> {
        let mut report = String::new();
        
        report.push_str("# Operational Dashboard - Critical Limits\n\n");
        report.push_str("## Current Status\n\n");
        
        if let Some(latest) = data.back() {
            // Status indicators
            let health_status = if latest.system_state.health_score > 0.8 { "ðŸŸ¢ HEALTHY" } 
                else if latest.system_state.health_score > 0.6 { "ðŸŸ¡ WARNING" } 
                else { "ðŸ”´ CRITICAL" };
            
            report.push_str(&format!("**System Status**: {}\n", health_status));
            report.push_str(&format!("**Uptime**: {:.1} hours\n", latest.system_state.uptime.as_secs() as f64 / 3600.0));
            report.push_str(&format!("**Load Level**: {:?}\n", latest.system_state.load_level));
            
            report.push_str("\n## Active Alerts\n\n");
            if latest.active_alerts.is_empty() {
                report.push_str("âœ… No active alerts\n");
            } else {
                for alert in &latest.active_alerts {
                    let severity_icon = match alert.severity {
                        AlertSeverity::Critical => "ðŸ”´",
                        AlertSeverity::High => "ðŸŸ ",
                        AlertSeverity::Medium => "ðŸŸ¡",
                        AlertSeverity::Low => "ðŸŸ¢",
                    };
                    report.push_str(&format!("{} **{}**: {}\n", severity_icon, alert.alert_type, alert.message));
                }
            }
            
            report.push_str("\n## Resource Utilization\n\n");
            report.push_str(&format!("- Memory: {:.1}%\n", latest.metrics.memory.usage_percent));
            report.push_str(&format!("- CPU: {:.1}%\n", latest.metrics.cpu.usage_percent));
            report.push_str(&format!("- Disk I/O: {:.1} MB/s read, {:.1} MB/s write\n", 
                latest.metrics.io.disk_read_mb_per_sec, latest.metrics.io.disk_write_mb_per_sec));
            report.push_str(&format!("- Network: {:.1} MB/s in, {:.1} MB/s out\n", 
                latest.metrics.network.in_mb_per_sec, latest.metrics.network.out_mb_per_sec));
        }
        
        report.push_str("\n## Immediate Actions Required\n\n");
        
        let mut action_count = 0;
        for analysis_result in analysis.values() {
            for recommendation in &analysis_result.recommendations {
                if matches!(recommendation.priority, RecommendationPriority::Critical | RecommendationPriority::Emergency) {
                    action_count += 1;
                    report.push_str(&format!("{}. **{}** ({})\n", action_count, recommendation.title, recommendation.timeline));
                }
            }
        }
        
        if action_count == 0 {
            report.push_str("âœ… No immediate actions required\n");
        }
        
        Ok(report)
    }

    /// Generate JSON report
    fn generate_json_report(
        report_type: &ReportType,
        data: &VecDeque<LimitsDataPoint>,
        analysis: &HashMap<String, AnalysisResult>,
    ) -> Result<String> {
        // Simplified JSON generation
        let mut json = String::new();
        json.push_str("{\n");
        json.push_str(&format!("  \"report_type\": \"{:?}\",\n", report_type));
        json.push_str(&format!("  \"generated_at\": \"{:?}\",\n", Instant::now()));
        json.push_str(&format!("  \"data_points\": {},\n", data.len()));
        json.push_str(&format!("  \"analysis_count\": {},\n", analysis.len()));
        
        if let Some(latest) = data.back() {
            json.push_str("  \"current_metrics\": {\n");
            json.push_str(&format!("    \"memory_usage_percent\": {:.1},\n", latest.metrics.memory.usage_percent));
            json.push_str(&format!("    \"cpu_usage_percent\": {:.1},\n", latest.metrics.cpu.usage_percent));
            json.push_str(&format!("    \"health_score\": {:.2}\n", latest.system_state.health_score));
            json.push_str("  },\n");
        }
        
        json.push_str("  \"summary\": {\n");
        json.push_str(&format!("    \"total_findings\": {},\n", 
            analysis.values().map(|a| a.findings.len()).sum::<usize>()));
        json.push_str(&format!("    \"total_recommendations\": {}\n", 
            analysis.values().map(|a| a.recommendations.len()).sum::<usize>()));
        json.push_str("  }\n");
        json.push_str("}");
        
        Ok(json)
    }

    /// Generate basic report
    fn generate_basic_report(
        report_type: &ReportType,
        data: &VecDeque<LimitsDataPoint>,
        analysis: &HashMap<String, AnalysisResult>,
    ) -> Result<String> {
        let mut report = String::new();
        
        report.push_str(&format!("Critical Limits Report - {:?}\n", report_type));
        report.push_str(&format!("Generated: {:?}\n", Instant::now()));
        report.push_str(&format!("Data Points: {}\n", data.len()));
        report.push_str(&format!("Analysis Results: {}\n", analysis.len()));
        
        if let Some(latest) = data.back() {
            report.push_str(&format!("Current Health Score: {:.1}%\n", latest.system_state.health_score * 100.0));
            report.push_str(&format!("Active Alerts: {}\n", latest.active_alerts.len()));
        }
        
        Ok(report)
    }

    /// Analyze trends
    fn analyze_trends_static(
        data: &VecDeque<LimitsDataPoint>,
        trend_analyzer: &Arc<Mutex<TrendAnalysisEngine>>,
    ) {
        let mut analyzer = trend_analyzer.lock().unwrap();
        
        // Add memory trend data
        for point in data.iter() {
            analyzer.trend_data.push_back(TrendDataPoint {
                timestamp: point.timestamp,
                metric: "memory_usage".to_string(),
                value: point.metrics.memory.usage_percent,
                quality: 1.0,
            });
        }
        
        // Limit trend data size
        while analyzer.trend_data.len() > 1000 {
            analyzer.trend_data.pop_front();
        }
        
        // Detect trends (simplified)
        if analyzer.trend_data.len() > 20 {
            // Memory trend detection
            let recent_memory: Vec<f64> = analyzer.trend_data.iter()
                .filter(|d| d.metric == "memory_usage")
                .rev()
                .take(20)
                .map(|d| d.value)
                .collect();
            
            if let Some(slope) = Self::detect_trend(&recent_memory) {
                if slope.abs() > 1.0 {
                    let trend = DetectedTrend {
                        id: "memory_trend_001".to_string(),
                        metric: "memory_usage".to_string(),
                        direction: if slope > 0.0 { TrendDirection::Increasing } else { TrendDirection::Decreasing },
                        strength: slope.abs() / 10.0,
                        duration: Duration::from_secs(1200), // 20 minutes
                        slope,
                        confidence: 0.8,
                        start_time: Instant::now() - Duration::from_secs(1200),
                    };
                    
                    analyzer.detected_trends.push(trend);
                }
            }
        }
        
        // Limit detected trends
        if analyzer.detected_trends.len() > 50 {
            analyzer.detected_trends.remove(0);
        }
    }

    /// Generate predictions
    fn generate_predictions_static(
        data: &VecDeque<LimitsDataPoint>,
        prediction_engine: &Arc<Mutex<PredictionEngine>>,
    ) {
        let mut engine = prediction_engine.lock().unwrap();
        
        // Generate memory usage prediction
        let memory_values: Vec<f64> = data.iter().map(|d| d.metrics.memory.usage_percent).collect();
        if memory_values.len() >= 10 {
            if let Some(trend) = Self::detect_trend(&memory_values) {
                let current_value = memory_values.last().cloned().unwrap_or(0.0);
                let predicted_value = current_value + trend * 12.0; // Predict 12 time units ahead
                
                let prediction = PredictionResult {
                    id: "memory_prediction_001".to_string(),
                    metric: "memory_usage_percent".to_string(),
                    timestamp: Instant::now(),
                    predicted_value,
                    confidence: 0.75,
                    time_horizon: Duration::from_secs(3600), // 1 hour
                    model_name: "linear_trend".to_string(),
                };
                
                engine.prediction_history.push(prediction);
            }
        }
        
        // Limit prediction history
        if engine.prediction_history.len() > 100 {
            engine.prediction_history.remove(0);
        }
    }

    /// Stop reporting
    pub fn stop_reporting(&self) {
        self.reporting_active.store(false, Ordering::SeqCst);
        self.analysis_active.store(false, Ordering::SeqCst);
        println!("ðŸ›‘ Critical limits reporting system stopped");
    }

    /// Get generated reports
    pub fn get_generated_reports(&self) -> HashMap<String, GeneratedReport> {
        self.generated_reports.lock().unwrap().clone()
    }

    /// Get report statistics
    pub fn get_report_statistics(&self) -> ReportStatistics {
        self.report_statistics.lock().unwrap().clone()
    }

    /// Generate comprehensive summary report
    pub fn generate_summary_report(&self) -> ComprehensiveSummaryReport {
        let reports = self.get_generated_reports();
        let statistics = self.get_report_statistics();
        let analysis_cache = self.analysis_cache.lock().unwrap();
        
        ComprehensiveSummaryReport {
            reporting_duration: self.config.report_generation_interval_secs,
            total_reports_generated: statistics.total_reports_generated,
            reports_by_type: statistics.reports_by_type,
            reports_by_format: statistics.reports_by_format,
            total_data_points_analyzed: statistics.total_data_points_processed,
            total_analysis_results: analysis_cache.len(),
            avg_report_generation_time: statistics.avg_generation_time,
            system_recommendations: self.extract_key_recommendations(&analysis_cache),
            critical_findings_summary: self.summarize_critical_findings(&analysis_cache),
            trend_summary: self.summarize_trends(),
            prediction_summary: self.summarize_predictions(),
        }
    }

    /// Extract key recommendations
    fn extract_key_recommendations(&self, analysis_cache: &HashMap<String, AnalysisResult>) -> Vec<String> {
        let mut recommendations = Vec::new();
        
        for analysis in analysis_cache.values() {
            for rec in &analysis.recommendations {
                if matches!(rec.priority, RecommendationPriority::Critical | RecommendationPriority::High) {
                    recommendations.push(format!("{}: {}", rec.title, rec.description));
                }
            }
        }
        
        recommendations.truncate(10); // Top 10 recommendations
        recommendations
    }

    /// Summarize critical findings
    fn summarize_critical_findings(&self, analysis_cache: &HashMap<String, AnalysisResult>) -> Vec<String> {
        let mut findings = Vec::new();
        
        for analysis in analysis_cache.values() {
            for finding in &analysis.findings {
                if matches!(finding.severity, FindingSeverity::Critical | FindingSeverity::High) {
                    findings.push(finding.description.clone());
                }
            }
        }
        
        findings.truncate(10); // Top 10 findings
        findings
    }

    /// Summarize trends
    fn summarize_trends(&self) -> Vec<String> {
        let analyzer = self.trend_analyzer.lock().unwrap();
        
        analyzer.detected_trends.iter()
            .take(5)
            .map(|trend| format!("{}: {:?} trend with {:.1}% strength", 
                trend.metric, trend.direction, trend.strength * 100.0))
            .collect()
    }

    /// Summarize predictions
    fn summarize_predictions(&self) -> Vec<String> {
        let engine = self.prediction_engine.lock().unwrap();
        
        engine.prediction_history.iter()
            .rev()
            .take(5)
            .map(|pred| format!("{}: Predicted value {:.1} with {:.1}% confidence", 
                pred.metric, pred.predicted_value, pred.confidence * 100.0))
            .collect()
    }
}

impl TrendAnalysisEngine {
    fn new() -> Self {
        Self {
            trend_data: VecDeque::new(),
            detected_trends: Vec::new(),
            config: TrendAnalysisConfig {
                min_trend_duration: Duration::from_secs(300),
                min_trend_strength: 0.1,
                analysis_window_size: 50,
                detection_sensitivity: 0.8,
            },
        }
    }
}

impl PredictionEngine {
    fn new() -> Self {
        Self {
            models: HashMap::new(),
            prediction_history: Vec::new(),
            config: PredictionEngineConfig {
                default_horizon: Duration::from_secs(3600),
                min_data_points: 20,
                retraining_interval: Duration::from_secs(3600),
                confidence_threshold: 0.7,
            },
        }
    }
}

impl ReportFormatter {
    fn new() -> Self {
        Self {
            templates: HashMap::new(),
            rules: Vec::new(),
            config: FormatterConfig {
                enable_syntax_highlighting: false,
                include_charts: true,
                chart_format: ChartFormat::ASCII,
                language: "en".to_string(),
                timezone: "UTC".to_string(),
            },
        }
    }
}

impl Default for ReportStatistics {
    fn default() -> Self {
        Self {
            total_reports_generated: 0,
            reports_by_type: HashMap::new(),
            reports_by_format: HashMap::new(),
            avg_generation_time: Duration::from_millis(0),
            total_data_points_processed: 0,
            cache_hit_rate: 0.0,
            distribution_success_rate: 0.0,
        }
    }
}

/// Comprehensive summary report
#[derive(Debug, Clone)]
pub struct ComprehensiveSummaryReport {
    /// Total reporting duration
    pub reporting_duration: u64,
    /// Total reports generated
    pub total_reports_generated: usize,
    /// Reports count by type
    pub reports_by_type: HashMap<ReportType, usize>,
    /// Reports count by format
    pub reports_by_format: HashMap<ReportFormat, usize>,
    /// Total data points analyzed
    pub total_data_points_analyzed: usize,
    /// Total analysis results
    pub total_analysis_results: usize,
    /// Average report generation time
    pub avg_report_generation_time: Duration,
    /// Key system recommendations
    pub system_recommendations: Vec<String>,
    /// Critical findings summary
    pub critical_findings_summary: Vec<String>,
    /// Trend summary
    pub trend_summary: Vec<String>,
    /// Prediction summary
    pub prediction_summary: Vec<String>,
}

// Tests
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_reporting_system_creation() -> Result<()> {
        let config = CriticalLimitsReportingConfig::default();
        let system = CriticalLimitsReportingSystem::new(config);
        
        assert!(!system.reporting_active.load(Ordering::SeqCst));
        assert!(!system.analysis_active.load(Ordering::SeqCst));
        
        Ok(())
    }

    #[test]
    fn test_limits_data_point_collection() -> Result<()> {
        let data_point = CriticalLimitsReportingSystem::collect_limits_data_point()?;
        
        assert!(data_point.metrics.memory.total_mb > 0.0);
        assert!(data_point.metrics.memory.usage_percent >= 0.0);
        assert!(data_point.metrics.cpu.usage_percent >= 0.0);
        assert!(data_point.system_state.health_score >= 0.0 && data_point.system_state.health_score <= 1.0);
        
        Ok(())
    }

    #[test]
    fn test_trend_detection() -> Result<()> {
        // Increasing trend
        let values = vec![10.0, 12.0, 14.0, 16.0, 18.0, 20.0];
        let trend = CriticalLimitsReportingSystem::detect_trend(&values);
        assert!(trend.is_some());
        assert!(trend.unwrap() > 0.0);
        
        // Decreasing trend
        let values = vec![20.0, 18.0, 16.0, 14.0, 12.0, 10.0];
        let trend = CriticalLimitsReportingSystem::detect_trend(&values);
        assert!(trend.is_some());
        assert!(trend.unwrap() < 0.0);
        
        // Stable trend
        let values = vec![15.0, 15.1, 14.9, 15.0, 15.2, 14.8];
        let trend = CriticalLimitsReportingSystem::detect_trend(&values);
        assert!(trend.is_some());
        assert!(trend.unwrap().abs() < 0.5);
        
        Ok(())
    }

    #[test]
    fn test_statistical_calculations() -> Result<()> {
        let values = vec![10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0];
        let stats = CriticalLimitsReportingSystem::calculate_statistics(&values);
        
        assert_eq!(stats.sample_count, 10);
        assert_eq!(stats.min, 10.0);
        assert_eq!(stats.max, 28.0);
        assert_eq!(stats.mean, 19.0);
        assert!(stats.std_deviation > 0.0);
        
        Ok(())
    }

    #[test]
    fn test_report_content_generation() -> Result<()> {
        let mut data = VecDeque::new();
        data.push_back(CriticalLimitsReportingSystem::collect_limits_data_point()?);
        
        let analysis = HashMap::new();
        let config = CriticalLimitsReportingConfig::default();
        
        // Test executive report
        let executive_report = CriticalLimitsReportingSystem::generate_executive_report(
            &ReportType::LimitsIdentification,
            &data,
            &analysis,
        )?;
        assert!(executive_report.contains("Executive Summary"));
        assert!(executive_report.contains("Key Findings"));
        
        // Test technical report
        let technical_report = CriticalLimitsReportingSystem::generate_technical_report(
            &ReportType::LimitsIdentification,
            &data,
            &analysis,
        )?;
        assert!(technical_report.contains("Technical Analysis"));
        assert!(technical_report.contains("System Metrics"));
        
        // Test operational report
        let operational_report = CriticalLimitsReportingSystem::generate_operational_report(
            &ReportType::LimitsIdentification,
            &data,
            &analysis,
        )?;
        assert!(operational_report.contains("Operational Dashboard"));
        assert!(operational_report.contains("Current Status"));
        
        // Test JSON report
        let json_report = CriticalLimitsReportingSystem::generate_json_report(
            &ReportType::LimitsIdentification,
            &data,
            &analysis,
        )?;
        assert!(json_report.contains("report_type"));
        assert!(json_report.contains("current_metrics"));
        
        Ok(())
    }

    #[test]
    fn test_recommendation_generation() -> Result<()> {
        let findings = vec![
            Finding {
                id: "test_finding".to_string(),
                finding_type: FindingType::CapacityLimitApproaching,
                description: "Memory usage approaching limit".to_string(),
                severity: FindingSeverity::Critical,
                supporting_data: vec![],
                impact: ImpactAssessment {
                    performance_impact: 0.8,
                    availability_impact: 0.7,
                    cost_impact: 0.3,
                    user_experience_impact: 0.6,
                    overall_impact: 0.7,
                },
            }
        ];
        
        let recommendations = CriticalLimitsReportingSystem::generate_recommendations_from_findings(&findings);
        assert!(!recommendations.is_empty());
        assert_eq!(recommendations[0].recommendation_type, RecommendationType::CapacityPlanning);
        assert_eq!(recommendations[0].priority, RecommendationPriority::Critical);
        
        Ok(())
    }

    #[test]
    fn test_short_reporting_session() -> Result<()> {
        let config = CriticalLimitsReportingConfig {
            report_generation_interval_secs: 5, // Very short interval
            min_data_points_for_analysis: 3,   // Low threshold for testing
            enable_predictive_analysis: false, // Disable for faster test
            enable_trend_visualization: false,
            ..Default::default()
        };
        
        let system = CriticalLimitsReportingSystem::new(config);
        
        // Start reporting
        system.start_reporting()?;
        
        // Let it run briefly
        thread::sleep(Duration::from_secs(2));
        
        // Check we have some data
        let data = system.historical_data.lock().unwrap();
        assert!(!data.is_empty());
        drop(data);
        
        // Stop reporting
        system.stop_reporting();
        
        Ok(())
    }

    #[test]
    fn test_comprehensive_reporting_workflow() -> Result<()> {
        println!("ðŸ§ª Testing comprehensive critical limits reporting workflow...");
        
        let config = CriticalLimitsReportingConfig {
            report_generation_interval_secs: 3, // Fast generation
            historical_retention_days: 1,      // Short retention for testing
            min_data_points_for_analysis: 5,   // Low threshold
            enable_predictive_analysis: true,
            enable_trend_visualization: true,
            enable_correlation_analysis: true,
            enable_automated_recommendations: true,
            report_types: vec![
                ReportType::LimitsIdentification,
                ReportType::TrendAnalysis,
                ReportType::SystemHealth,
            ],
            report_formats: vec![
                ReportFormat::Executive,
                ReportFormat::Technical,
                ReportFormat::JSON,
            ],
            ..Default::default()
        };
        
        let system = CriticalLimitsReportingSystem::new(config);
        
        // Start reporting
        system.start_reporting()?;
        
        // Let reporting run and generate data
        thread::sleep(Duration::from_secs(5));
        
        // Check data collection
        let data = system.historical_data.lock().unwrap();
        assert!(!data.is_empty(), "Should have collected data points");
        let data_count = data.len();
        drop(data);
        
        // Check analysis cache
        let analysis = system.analysis_cache.lock().unwrap();
        let analysis_count = analysis.len();
        drop(analysis);
        
        // Stop reporting
        system.stop_reporting();
        
        // Generate summary report
        let summary = system.generate_summary_report();
        
        println!("âœ… Comprehensive reporting completed:");
        println!("   ðŸ“Š Data points collected: {}", data_count);
        println!("   ðŸ” Analysis results: {}", analysis_count);
        println!("   ðŸ“‹ Reports generated: {}", summary.total_reports_generated);
        println!("   ðŸ“ˆ Trends detected: {}", summary.trend_summary.len());
        println!("   ðŸ”® Predictions made: {}", summary.prediction_summary.len());
        println!("   ðŸ’¡ Recommendations: {}", summary.system_recommendations.len());
        println!("   ðŸš¨ Critical findings: {}", summary.critical_findings_summary.len());
        
        for (i, recommendation) in summary.system_recommendations.iter().enumerate() {
            println!("      {}. {}", i + 1, recommendation);
        }
        
        // Verify meaningful reporting occurred
        assert!(data_count > 0, "Should have collected data");
        assert!(summary.total_reports_generated >= 0, "Should track report generation");
        
        Ok(())
    }
}